# Improved Recipe Generation Model Configuration

# Data settings
data:
  dataset_name: "recipe_nlg"
  train_split: "train"
  validation_split: "validation"
  prompt_template: "You are a professional chef. Create a complete recipe using these ingredients: {ingredients}\n\nRecipe:\n"
  response_key: "directions"
  max_length: 384  # Increased for more detailed recipes
  max_train_samples: 20000  # More training examples
  cache_dir: "./data/processed/generation"

# Model settings
model:
  name: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
  save_dir: "./models/recipe_assistant_improved"
  load_in_8bit: true

# Training settings
training:
  batch_size: 1
  gradient_accumulation_steps: 16
  num_train_epochs: 2  # More epochs for better learning
  learning_rate: 1.0e-5  # Slightly lower learning rate
  weight_decay: 0.01
  warmup_steps: 200
  save_steps: 500
  save_total_limit: 1
  logging_dir: "./logs/recipe_assistant_improved"
  evaluation_strategy: "steps"
  eval_steps: 500
  fp16: true
  lora:
    enabled: true
    r: 8  # Increased rank for more capacity
    alpha: 32
    dropout: 0.05
    target_modules: ["q_proj", "v_proj", "k_proj", "o_proj"]

# Testing settings
testing:
  test_examples_file: "data/processed/generation/test_examples_improved.json"
  generation_params:
    max_new_tokens: 384
    temperature: 0.8  # Slightly higher for more creativity
    top_p: 0.92
    top_k: 50
    do_sample: true
    repetition_penalty: 1.2  # Discourage repetition
  evaluation_metrics:
    - perplexity
    - rouge
